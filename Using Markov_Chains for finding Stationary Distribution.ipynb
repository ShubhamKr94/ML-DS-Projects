{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd737f1",
   "metadata": {},
   "source": [
    "# Worksheet 2: Markov Chains - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c118de9",
   "metadata": {},
   "source": [
    "## Simulation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d009f7",
   "metadata": {},
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af2b658",
   "metadata": {},
   "source": [
    "1. Edit the previous code to produce simulations of the  5 state Markov chain with transition matrix \n",
    "$$P = \n",
    "\\left( \\begin{matrix} 0& \\frac{1}{3} & \\frac{2}{3} & 0&0 \\\\\n",
    "\\frac{1}{4} & \\frac{1}{8} & \\frac{1}{8} & \\frac{1}{8}&\\frac{3}{8} \\\\\n",
    "\\frac{1}{2} & 0 & 0& \\frac{1}{4}&\\frac{1}{4}\\\\\n",
    "0&1&0&0&0 \\\\\n",
    "1&0&0&0&0\n",
    "\\end{matrix} \\right),$$\n",
    "starting in state 1.\n",
    "\n",
    "HINT: You can use the `sample` function or a `for` loop to avoid multiple `if` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9feb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X<-1 # initial state of the Markov Chain\n",
    "n<-10 # number of steps to simulate\n",
    "P <- matrix( c(0, 1/3, 2/3, 0,0 ,\n",
    "1/4, 1/8 , 1 /8   ,  1 /8  , 3 /8,\n",
    " 1 /2   , 0 , 0,  1 /4  , 1 /4,\n",
    "0,1,0,0,0,\n",
    "1,0,0,0,0),\n",
    " nrow=5, ncol=5, byrow = TRUE) \n",
    " # P matrix (values changed and number rows and columns)\n",
    "for( i in 1:n){\n",
    "    p<-P[X[i],] # Calculate the p values\n",
    "    X[i+1]<-sample(x=5, size=1, prob=p) # update the chain\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c48f18",
   "metadata": {},
   "source": [
    "## Estimating Hitting Probabilities and Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0a5a9",
   "metadata": {},
   "source": [
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5544330",
   "metadata": {},
   "source": [
    "Consider a Markov chain on 4 states with transition matrix\n",
    "$$P = \\left( \\begin{matrix} \\frac{1}{2}& \\frac{1}{4} & \\frac{1}{4}& 0 \\\\\n",
    "\\frac{1}{3} & 0 & \\frac{2}{3} & 0 \\\\\n",
    "0&\\frac{7}{8} & 0 & \\frac{1}{8} \\\\\n",
    "0&\\frac{1}{2}& \\frac{1}{4} & \\frac{1}{4}\n",
    "\\end{matrix} \\right). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6bab3",
   "metadata": {},
   "source": [
    "1.  Edit the previous code to simulate this chain starting at initial state 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e29ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X<-2 # initial state of the Markov Chain\n",
    "n<-10 # number of steps to simulate\n",
    "P <- matrix( c(  1/2,1/4,1/4, 0,\n",
    "1/3,0,2/3,0,\n",
    "0,7/8,0,1/8,\n",
    "0,1/2,1/4,1/4),\n",
    "nrow=4, ncol=4, byrow = TRUE) \n",
    "# P matrix (values changed and number rows and columns)\n",
    "for( i in 1:n){\n",
    "    p<-P[X[i],] # Calculate the p values\n",
    "    X[i+1]<-sample(x=4, size=1, prob=p) # update the chain\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1bd0e",
   "metadata": {},
   "source": [
    "2. By editing the code produce an  estimate  of the probability of hitting state 1 before state 4 after starting in state 2. \n",
    "\n",
    "HINT: In this exercise, apply the same constructs as above:  `while` loops, `if`-`else` statements and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2918db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials<-1000\n",
    "hitone<-0 #Counter for number of times state 1 is hit before state 4\n",
    "for( j in 1:trials){\n",
    "    X<-2 # initial state of the Markov Chain\n",
    "    P <- matrix( c(1/2 ,1/4,1/4,0,\n",
    "    1/3,0,2/3,0,\n",
    "    0, 7/8, 0,1/8 ,\n",
    "    0,1/2,1/4 ,1/4 ),\n",
    "    nrow=4, ncol=4, byrow = TRUE) # P matrix\n",
    "    i<-1 # Number of steps\n",
    "    while(X[i]>1 && X[i]<4){\n",
    "        p<-P[X[i],] # Calculate the p values\n",
    "        X[i+1]<-sample(x=4, size=1, prob=p) # update the chain\n",
    "        i<-i+1\n",
    "    }\n",
    "    if(X[i]==1){ \n",
    "        hitone<-hitone+1\n",
    "    }else{\n",
    "        hitone<- hitone+0\n",
    "    }\n",
    "}\n",
    "probest<-hitone/trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69a5c0",
   "metadata": {},
   "source": [
    "We then find an estimate of (will change slightly each time the above code is run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8843ca",
   "metadata": {},
   "source": [
    "3. Compare the previous estimate to the calculated value of the hitting probability.\n",
    "\n",
    "HINT: To calculate a hitting probability by hand, you can use a similar method to calculating absorption probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c62e5",
   "metadata": {},
   "source": [
    "To find the hitting probability we need to solve the equations\n",
    "$$\\alpha_i = P_{i,j} \\alpha_j,$$\n",
    "with $\\alpha_1=1$ and $\\alpha_4=0$. Here the equations are\n",
    "$$\\alpha_2 = \\frac{1}{3} \\alpha_1 + \\frac{2}{3} \\alpha_3 = \\frac{1}{3} +\\frac{2}{3} \\alpha_3 ,$$\n",
    "$$\\alpha_3= \\frac{7}{8} \\alpha_2 +\\frac{1}{8} \\alpha_4 =\\frac{7}{8} \\alpha_2.$$\n",
    "So $\\alpha_2= \\frac{4}{5}$, which is close to the estimate produced before. This also give the probability of hitting state 1 before state 4 starting from state 3 as $\\alpha_3 = \\frac{7}{10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f716cb",
   "metadata": {},
   "source": [
    "4. Repeat the above exercises starting at state 3 instead of state 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837cb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials<-1000\n",
    "hitone<-0 #Counter for number of times state 1 is hit before state 4\n",
    "for( j in 1:trials){\n",
    "    X<-3# initial state of the Markov Chain\n",
    "    P <- matrix( c(1/2 ,1/4,1/4,0,\n",
    "    1/3,0,2/3,0,\n",
    "    0, 7/8, 0,1/8 ,\n",
    "    0,1/2,1/4 ,1/4 ),\n",
    "    nrow=4, ncol=4, byrow = TRUE) # P matrix\n",
    "    i<-1 # Number of steps\n",
    "    while(X[i]>1 && X[i]<4){\n",
    "        p<-P[X[i],] # Calculate the p values\n",
    "        X[i+1]<-sample(x=4, size=1, prob=p) # update the chain\n",
    "        i<-i+1\n",
    "    }\n",
    "    if(X[i]==1){ \n",
    "        hitone<-hitone+1\n",
    "    }else{\n",
    "        hitone<- hitone+0\n",
    "    }\n",
    "}\n",
    "probest<-hitone/trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f42a6",
   "metadata": {},
   "source": [
    "We then find an estimate of $\\alpha$ (will change slightly each time the above code is run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "probest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4c491",
   "metadata": {},
   "source": [
    "5. Edit the code to estimate the mean time to hit the state 1 starting at state 2. Repeat this starting at states 3 and 4. Compare these to the exact calculations of the mean hitting time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0549dff",
   "metadata": {},
   "source": [
    "Code for estimating time to hit state 1 starting at state 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7708e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials<-1000\n",
    "totalsteps<-0 #Counter for the total number of steps taken\n",
    "for( j in 1:trials){\n",
    "    X<-2 # initial state of the Markov Chain\n",
    "    P <- matrix( c(1/2 ,1/4,1/4,0,\n",
    "    1/3,0,2/3,0,\n",
    "    0, 7/8, 0,1/8 ,\n",
    "    0,1/2,1/4 ,1/4 ),\n",
    "    nrow=4, ncol=4, byrow = TRUE) # P matrix\n",
    "    i<-1 # Number of steps\n",
    "    while(X[i]>1){\n",
    "        p<-P[X[i],] # Calculate the p values\n",
    "        X[i+1]<-sample(x=4, size=1, prob=p) # update the chain\n",
    "        i<-i+1\n",
    "    }\n",
    "  totalsteps<-totalsteps+(i-1)\n",
    "}\n",
    "timeest<-totalsteps/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a38fb",
   "metadata": {},
   "source": [
    "Code for estimating time to hit state 1 starting at state 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials<-1000\n",
    "totalsteps<-0 #Counter for the total number of steps taken \n",
    "for( j in 1:trials){\n",
    "    X<-3 # initial state of the Markov Chain\n",
    "    P <- matrix( c(1/2 ,1/4,1/4,0,\n",
    "    1/3,0,2/3,0,\n",
    "    0, 7/8, 0,1/8 ,\n",
    "    0,1/2,1/4 ,1/4 ),\n",
    "    nrow=4, ncol=4, byrow = TRUE) # P matrix\n",
    "    i<-1 # Number of steps\n",
    "    while(X[i]>1 ){\n",
    "        p<-P[X[i],] # Calculate the p values\n",
    "        X[i+1]<-sample(x=4, size=1, prob=p) # update the chain\n",
    "        i<-i+1\n",
    "    }\n",
    "  totalsteps<-totalsteps+(i-1)\n",
    "}\n",
    "timeest<-totalsteps/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce62db",
   "metadata": {},
   "source": [
    "Code for estimating time to hit state 1 starting at state 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d69aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials<-1000\n",
    "totalsteps<-0 #Counter for the total number of steps taken \n",
    "for( j in 1:trials){\n",
    "    X<-4 # initial state of the Markov Chain\n",
    "    P <- matrix( c(1/2 ,1/4,1/4,0,\n",
    "    1/3,0,2/3,0,\n",
    "    0, 7/8, 0,1/8 ,\n",
    "    0,1/2,1/4 ,1/4 ),\n",
    "    nrow=4, ncol=4, byrow = TRUE) # P matrix\n",
    "    i<-1 # Number of steps\n",
    "    while(X[i]>1 ){\n",
    "        p<-P[X[i],] # Calculate the p values\n",
    "        X[i+1]<-sample(x=4, size=1, prob=p) # update the chain\n",
    "        i<-i+1\n",
    "    }\n",
    "  totalsteps<-totalsteps+(i-1)\n",
    "}\n",
    "timeest<-totalsteps/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eecd32",
   "metadata": {},
   "source": [
    "To find the expected time to hit state one we need to solve the equations\n",
    "\n",
    "$$t_i = P_{i,j} t_j +1,$$\n",
    "\n",
    "with the edge  condition that $t_1 =0.$\n",
    "\n",
    "So here we have\n",
    "$$t_2 = \\frac{1}{3} t_1 + \\frac{2}{3} t_3 +1= \\frac{2}{3} t_3 +1,$$\n",
    "\n",
    "$$t_3= \\frac{7}{8} t_2 +\\frac{1}{8} t_4 +1,$$\n",
    "\n",
    "$$t_4 = \\frac{1}{2} t_2 +\\frac{1}{4} t_3+\\frac{1}{4} t_4 +1.$$\n",
    "\n",
    "Solving these gives\n",
    "\n",
    "$$t_2 = \\frac{125}{23}=5.43,$$\n",
    "\n",
    "$$t_3= \\frac{153}{23}=6.65,$$\n",
    "\n",
    "$$t_4= \\frac{165}{23}=7.17.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd67dcd3",
   "metadata": {},
   "source": [
    "6. Produce a histogram of the hitting times of state 1 starting  at state 2 using 1000 simulations of the Markov chain. \n",
    "\n",
    "HINT: `hist` is the function to plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d95e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials<-1000\n",
    "results<-0 #results\n",
    "for( j in 1:trials){\n",
    "    X<-2 # initial state of the Markov Chain\n",
    "    P <- matrix( c(1/2 ,1/4,1/4,0,\n",
    "    1/3,0,2/3,0,\n",
    "    0, 7/8, 0,1/8 ,\n",
    "    0,1/2,1/4 ,1/4 ),\n",
    "    nrow=4, ncol=4, byrow = TRUE) # P matrix\n",
    "    i<-1 # Number of steps\n",
    "    while(X[i]>1){\n",
    "        p<-P[X[i],] # Calculate the p values\n",
    "        X[i+1]<-sample(x=4, size=1, prob=p) # update the chain\n",
    "        i<-i+1\n",
    "    }\n",
    "  results[j]<-(i-1)\n",
    "}\n",
    "hist(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10bd46b",
   "metadata": {},
   "source": [
    "## Stationary and Limiting Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba907c24",
   "metadata": {},
   "source": [
    "### Exercises: Finite aperiodic chain with single closed class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eca212",
   "metadata": {},
   "source": [
    "Consider the Markov chain, $\\{X_n\\}_{n\\geq0}$, on 5 states with transition matrix,\n",
    "$$P = \\left( \\begin{matrix} \\frac{1}{2}& \\frac{1}{3}&\\frac{1}{6}&0&0\\\\\n",
    "\\frac{1}{4}&0&\\frac{1}{4}&\\frac{1}{4}&\\frac{1}{4}\\\\\n",
    "0&0&\\frac{1}{8}&\\frac{1}{8}&\\frac{3}{4}\\\\\n",
    "\\frac{1}{2}&\\frac{1}{4}&\\frac{1}{8}&\\frac{1}{16}&\\frac{1}{16}\\\\\n",
    "1&0&0&0&0\n",
    "\\end{matrix} \\right). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ecb20",
   "metadata": {},
   "source": [
    "1. Find the associated stationary distribution (without using **R**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd41be",
   "metadata": {},
   "source": [
    "We need to solve $\\pi = \\pi P$ which gives the following set of 5 equations:\n",
    "\\begin{align*}\n",
    "\\pi_1 =& \\frac{1}{2}\\pi_1 + \\frac{1}{4} \\pi_2 +\\frac{1}{2}\\pi_4 + \\pi_5 \\\\\n",
    "\\pi_2 =& \\frac{1}{3}\\pi_1 +\\frac{1}{4}\\pi_4  \\\\\n",
    "\\pi_3 =& \\frac{1}{6}\\pi_1 + \\frac{1}{4} \\pi_2 +\\frac{1}{8}\\pi_3+\\frac{1}{8}\\pi_4  \\\\\n",
    "\\pi_4=&  \\frac{1}{4} \\pi_2 +\\frac{1}{8}\\pi_3+\\frac{1}{16}\\pi_4  \\\\\n",
    "\\pi_5=&  \\frac{1}{4} \\pi_2 +\\frac{3}{4}\\pi_3+\\frac{1}{16}\\pi_4 \n",
    "\\end{align*}\n",
    "\n",
    "With the additional condition $\\sum \\pi_i = 1$ we obtain\n",
    " $$\\pi_1 = 0.462,\\\\ \\pi_2 = 0.170,\\\\ \\pi_3 = 0.146,\\\\ \\pi_4 = 0.065,\\\\ \\pi_5 = 0.156$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116573cb",
   "metadata": {},
   "source": [
    "2. Produce code to simulate this Markov chain and plot the proportion of simulations in each state against the number of steps for 1000 independent realisations of the Markov chain each starting at state 1. Repeat with each chain starting at state 3. Compare these plots to the stationary distribution and comment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b881c9b",
   "metadata": {},
   "source": [
    "We first create a function called `simulate.chain` that we can reuse for future exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d28d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate.chain <- function (trials, n, P, X0=1){\n",
    "     m <- dim(P)[1]\n",
    "\n",
    "    #Vectors to store proportion of simulations in each state\n",
    "     levels<-matrix(0, nrow=m, ncol=n+1)\n",
    "\n",
    "    for(j in 1:trials){\n",
    "        X<-X0 # initial state of the Markov Chain\n",
    "        levels[X, 1] = levels[X, 1] + 1  #Record the initial state\n",
    "        for( i in 1:n){\n",
    "            p<-P[X[i],] # Get the p values\n",
    "            X[i+1]<-sample(x=m, size=1, prob=p) # update the chain\n",
    "            levels[X[i+1], i+1] = levels[X[i+1], i+1] + 1\n",
    "        }\n",
    "    }\n",
    "    levels<-levels/trials\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03830d70",
   "metadata": {},
   "source": [
    "We now use the above function to simulate this particular Markov chain 1000 times starting in state 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m <- 5\n",
    "n <- 20\n",
    "P <- matrix( c(1/2, 1/3, 1/6,0,0, \n",
    "1/4,0, 1/4, 1/4,1/4,\n",
    "0, 0,1/8,1/8,3/4,\n",
    "1/2,1/4,1/8,1/16,1/16,\n",
    "1,0,0,0,0), nrow=m, ncol=m, byrow = TRUE) # P matrix\n",
    "\n",
    "levels <- simulate.chain(1000, n, P, 1)\n",
    "\n",
    "#Plot the evolution of the proportion at each state\n",
    "plot(levels[1,], type='l', xlim=c(0,n+1), ylim=c(0,1), xlab='Steps',\n",
    " ylab='Proportion', col=1,lwd=2)\n",
    "for (i in 2:m)\n",
    "   lines(levels[i,], col=i, lwd=2)\n",
    "\n",
    "labels <- sapply(1:m, function(x) { paste(\"State\", x)})\n",
    "# OR: labels = c('State 1', 'State 2', 'State 3', 'State 4', 'State 5')\n",
    "legend(15,1, labels, col=1:m, lwd=2)\n",
    "\n",
    "#lines representing the stationary distribution\n",
    "exact <- c(0.462, 0.170, 0.146, 0.065, 0.156)\n",
    "for (i in 1:m)\n",
    "     lines(exact[i]*rep(1,n+1), col=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9df65",
   "metadata": {},
   "source": [
    "Here is the code starting in state 3 instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "m <- 5\n",
    "n <- 20\n",
    "P <- matrix( c(1/2, 1/3, 1/6,0,0, \n",
    "1/4,0, 1/4, 1/4,1/4,\n",
    "0, 0,1/8,1/8,3/4,\n",
    "1/2,1/4,1/8,1/16,1/16,\n",
    "1,0,0,0,0), nrow=m, ncol=m, byrow = TRUE) # P matrix\n",
    "\n",
    "levels <- simulate.chain(1000, n, P, 3)\n",
    "\n",
    "#Plot the evolution of the proportion at each state\n",
    "plot(levels[1,], type='l', xlim=c(0,n+1), ylim=c(0,1), xlab='Steps',\n",
    " ylab='Proportion', col=1,lwd=2)\n",
    "for (i in 2:m)\n",
    "   lines(levels[i,], col=i, lwd=2)\n",
    "\n",
    "labels <- sapply(1:m, function(x) { paste(\"State\", x)})\n",
    "# OR: labels = c('State 1', 'State 2', 'State 3', 'State 4', 'State 5')\n",
    "legend(15,1, labels, col=1:m, lwd=2)\n",
    "\n",
    "#lines representing the stationary distribution\n",
    "exact <- c(0.462, 0.170, 0.146, 0.065, 0.156)\n",
    "for (i in 1:m)\n",
    "     lines(exact[i]*rep(1,n+1), col=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba69dbe",
   "metadata": {},
   "source": [
    "It does not matter which state the Markov chain starts in it  quickly converges to the stationary distribution calculated in the first question. We see that even by step 7  the stationary distribution is a good approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57277dd8",
   "metadata": {},
   "source": [
    "### Exercises: Infinite recurrent aperiodic chain with a single closed class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8897bd5",
   "metadata": {},
   "source": [
    "1. Rewrite the code for simulating a simple random walk from the previous worksheet to include the reflecting boundary at 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8af958",
   "metadata": {},
   "outputs": [],
   "source": [
    "refl.random.walk <- function (n, a=0){\n",
    "    a<-0 # initial level\n",
    "    S<-a # initialize the random walk\n",
    "    p<- 0.55  # probability of  -1\n",
    "    for( i in 1:n){\n",
    "         y<-runif(1)\n",
    "         if(y>p){\n",
    "            x <- 1\n",
    "          }else{\n",
    "              if(S[i]>0){ #Test whether we are at the boundary or not\n",
    "              x<- -1 #Not at boundary so normal step\n",
    "              }else {\n",
    "              x<-0  #At boundary so no change\n",
    "              }\n",
    "          }\n",
    "\n",
    "        S[i+1]<-S[i] +x # update the random walk\n",
    "    }\n",
    "    S  # Return S\n",
    "}\n",
    "\n",
    "n <- 100\n",
    "S <- refl.random.walk(n)\n",
    "plot(0:n, S, type='l') #plot the random walk sample path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f223e",
   "metadata": {},
   "source": [
    "2. Calculate the stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd0109",
   "metadata": {},
   "source": [
    "To find the stationary distribution we need to solve the questions:\n",
    "\n",
    "\\begin{align*}\n",
    "\\pi_0 &= 0.55 \\pi_0 + 0.55 \\pi_1 \\\\\n",
    "\\pi_i & = 0.45 \\pi_{i-1} + 0.55 \\pi_{i+1} \\; \\textrm{ for all }i>0\\\\\n",
    "\\sum_{i =0}^\\infty \\pi_i &= 1\n",
    "\\end{align*}\n",
    "\n",
    "Solving the first two equations we obtain\n",
    "\n",
    "$$\\pi_i = \\left( \\frac{9}{11} \\right)^i \\pi_0,$$\n",
    "\n",
    "which we substitute into the third equation to obtain\n",
    "\n",
    "$$\\pi_0 \\sum_{i =0}^\\infty \\left( \\frac{9}{11}\\right)^i = 1.$$\n",
    "\n",
    "Solving this gives the stationary distribution as\n",
    "\n",
    "$$ \\pi_i = \\left( \\frac{9}{11}\\right)^i \\left( \\frac{2}{11} \\right).$$\n",
    "\n",
    "We will add this to the histogram in the next exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf86ff",
   "metadata": {},
   "source": [
    "3. Simulate this process for 200 steps. Using 1000 independent simulations produce a histogram of $S_{200}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result<-0\n",
    "trials<-1000\n",
    "n <- 200\n",
    "for( j in 1:trials){\n",
    "    S = refl.random.walk(n)\n",
    "    result[j]<-S[n+1]\n",
    "}\n",
    "hist(result, breaks=(0:(max(result)+1))-0.5, probability=TRUE) \n",
    "#We set bin widths so there is one integer in each bin\n",
    "lines(0:26, (2/11)*(9/11)^(0:26))\n",
    "#addition of stationary distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8091d",
   "metadata": {},
   "source": [
    "We see from the histogram that the stationary distribution and the empirical distribution are close. This is to be  expected as the Markov chain converges to its stationary distribution, since the chain is positive recurrent and aperiodic.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee8b88",
   "metadata": {},
   "source": [
    "### Exercises: Periodic chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d527573",
   "metadata": {},
   "source": [
    "Let $\\{X_n\\}_{n\\geq0}$ be a Markov chain on 6 states with transition matrix,\n",
    "$$P= \\left( \\begin{matrix} 0&0&0&\\frac{1}{2}&0&\\frac{1}{2}\\\\\n",
    " \\frac{1}{2}&0&0&0&\\frac{1}{2}&0\\\\\n",
    "  \\frac{1}{2}&0&0&0&\\frac{1}{2}&0\\\\\n",
    "   0&\\frac{1}{2}&\\frac{1}{2}&0&0&0\\\\\n",
    "  0&0&0&\\frac{1}{2}&0&\\frac{1}{2}\\\\\n",
    " 0&\\frac{1}{2}&\\frac{1}{2}&0&0&0\n",
    " \\end{matrix} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01155bb1",
   "metadata": {},
   "source": [
    "1. Calculate the associated stationary distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7612e",
   "metadata": {},
   "source": [
    "We solve $$\\pi = \\pi P$$ \n",
    "\n",
    "with the additional condition $\\sum \\pi_i = 1$ and find the stationary distribution is \n",
    "\n",
    " $$\\pi = \\left( \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6},\\frac{1}{6} \\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30193f17",
   "metadata": {},
   "source": [
    "2. Simulate the Markov chain with initial state 1. As for the first exercise produce a plot of the proportion of simulations in each state for the first 20 steps. Compare this to the stationary distribution and comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6258b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m <- 6\n",
    "n <- 20\n",
    "P <- matrix( c(0, 0, 0,1/2,0,1/2,\n",
    "1/2,0, 0, 0,1/2,0,\n",
    "1/2,0, 0, 0,1/2,0,\n",
    "0,1/2,1/2,0,0,0,\n",
    "0, 0, 0,1/2,0,1/2,\n",
    "0,1/2,1/2,0,0,0),\n",
    " nrow=m, ncol=m, byrow = TRUE) # P matrix\n",
    "\n",
    "levels <- simulate.chain(1000, n, P, 1)\n",
    "\n",
    "#Plot the evolution of the proportion at each state\n",
    "plot(levels[1,], type='l', xlim=c(0,n+1), ylim=c(0,1), xlab='Steps',\n",
    " ylab='Proportion', col=1,lwd=2)\n",
    "for (i in 2:m)\n",
    "   lines(levels[i,], col=i, lwd=2)\n",
    "labels <- sapply(1:m, function(x) { paste(\"State\", x)})\n",
    "legend(15,1, labels, col=1:m, lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e593b",
   "metadata": {},
   "source": [
    "It is clear from the plot that in this case the Markov chain does not converge to the stationary distribution. This occurs since the Markov chain is periodic. It can be seen either from the plot produced or by examining the structure of the transition matrix that the chain has period 3.\n",
    " \n",
    "We can separate the state space into 3 disjoint sets,\n",
    "\n",
    " $$S_1 = \\{1,5\\}, \\; S_2 = \\{4,6\\},\\;  S_3 =\\{2,3\\} $$\n",
    " \n",
    "such that, for any $i = 1,2,3$ and for any $x \\in S_i$,\n",
    "\n",
    " $$\\mathbb{P} (X_1 \\in S_{i+1} | X_0 = x) = 1,$$\n",
    "\n",
    "where $S_4= S_1$. This proves the chain has period 3.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bdf9f",
   "metadata": {},
   "source": [
    "### Exercises: Multiple closed classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f6a27",
   "metadata": {},
   "source": [
    "We now consider a Markov chain with two closed classes and one open class. Here $\\{X_n\\}_{n\\geq0}$ has 5 states with transition matrix\n",
    "\n",
    " $$P= \\left(\\begin{matrix} \\frac{2}{3}& 0 &0& \\frac{1}{3}& 0 \\\\\n",
    "0& 1 &0&0& 0 \\\\\n",
    "\\frac{1}{4}& \\frac{1}{4} &0&\\frac{1}{4}& \\frac{1}{4} \\\\\n",
    "\\frac{1}{8}& 0 &0&\\frac{7}{8}& 0 \\\\\n",
    "0& \\frac{3}{8}&\\frac{1}{4}&\\frac{1}{4}& \\frac{1}{8}\n",
    "\\end{matrix} \\right).\n",
    " $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0b99a",
   "metadata": {},
   "source": [
    "1. Identify all the closed and open classes in this Markov chain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a561e09",
   "metadata": {},
   "source": [
    "|Class       |Type                |\n",
    "|:----------:|:------------------:|\n",
    "|{1,4}       |closed              |\n",
    "|{2}         |closed (absorbing)  |\n",
    "|{3,5}       |open                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefbb4b",
   "metadata": {},
   "source": [
    "2. Produce a plot for each starting state of the evolution of the proportion of simulations in each state over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m <- 5\n",
    "n <- 20\n",
    "P <- matrix( c(2/3, 0, 0,1/3,0,\n",
    "0,1, 0, 0,0,\n",
    "1/4, 1/4,0,1/4,1/4,\n",
    "1/8,0,0,7/8,0,\n",
    "0,3/8,1/4,1/4,1/8),\n",
    " nrow=m, ncol=m, byrow = TRUE) # P matrix\n",
    "\n",
    "# par(mfrow=c(2, 3))  # if copying into RStudio, can add this in\n",
    "labels <- sapply(1:m, function(x) { paste(\"State\", x)})\n",
    "for (i in 1:5)\n",
    "{\n",
    "     levels = simulate.chain(1000, n, P, i)\n",
    "\n",
    "     #Plot the evolution of the proportion at each state\n",
    "     plot(levels[1,], type='l', xlim=c(0,n+1), ylim=c(0,1), xlab='Steps',\n",
    "      ylab='Proportion', col=1,lwd=2, main=paste(\"Initial state\", i))\n",
    "     for (i in 2:m)\n",
    "        lines(levels[i,], col=i, lwd=2)\n",
    "     legend(15,1, labels, col=1:m, lwd=rep(2,m))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c2768",
   "metadata": {},
   "source": [
    "Note that the limit distribution now depends to the initial state. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536e100",
   "metadata": {},
   "source": [
    "3. Find all the associated stationary distributions for this Markov chain and the absorption probabilities for each closed class from the open states. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d781e",
   "metadata": {},
   "source": [
    "To find all stationary distributions for the Markov chain we need to find the associated stationary distributions for each of the closed classes.  For the closed class $\\{2\\}$ the stationary distribution is entirely supported on this state, hence the associated stationary distribution is $(0,1,0,0,0)$. \n",
    " \n",
    " For the closed class $\\{1,4\\}$ we need to solve the equations\n",
    " \n",
    " $$ \\pi_1 = \\frac{2}{3}\\pi_1 + \\frac{1}{8} \\pi_4 $$\n",
    " \n",
    " $$\\pi_4 = \\frac{1}{3} \\pi_1 + \\frac{7}{8}\\pi_4$$\n",
    " \n",
    " $$1= \\pi_1+\\pi_4.$$\n",
    " \n",
    " Solving these gives the stationary distribution associated with this class as \n",
    "$(\\frac{3}{11},0,0,\\frac{8}{11}, 0)$. Therefore all the stationary distributions for this Markov chain are given by \n",
    "\n",
    "$$\\left(\\frac{3\\lambda}{11},(1-\\lambda),0,\\frac{8\\lambda}{11}, 0\\right).$$\n",
    "\n",
    "with $0\\leq\\lambda \\leq 1$.\n",
    "\n",
    "We calculate the probability of being absorbed into the state 2 from state 3 and 5 using the following equations:\n",
    "\n",
    "$$\\alpha_3 = \\frac{1}{4} \\left( \\alpha_1 + \\alpha_2 + \\alpha_4+\\alpha_5\\right)$$\n",
    "\n",
    "$$\\alpha_5 = \\frac{3}{8}\\alpha_2 +\\frac{1}{4}\\alpha_3+\\frac{1}{4}\\alpha_4+\\frac{1}{8} \\alpha_5$$\n",
    "\n",
    "$$\\alpha_1=\\alpha_4 = 0, \\; \\alpha_2 = 1.$$\n",
    "\n",
    "This gives the absorption probability of state 2 from state 3 is $\\frac{5}{13}$ and from state 5 is $\\frac{7}{13}$. Hence the absorption probability of the closed class $\\{1,4\\}$ from state 3 is $\\frac{8}{13}$ and from state 5 is $\\frac{6}{13}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5605e6",
   "metadata": {},
   "source": [
    "4. Use this information to calculate the limiting distributions for each starting state and compare these to the plots produced previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae1dcd",
   "metadata": {},
   "source": [
    "Using the absorption probabilities from the previous question we obtain the limit distributions as\n",
    "\n",
    "|State      |Distribution                |\n",
    "|:----------:|:------------------:|\n",
    "|1       |($\\frac{3}{11}$,0,0,$\\frac{8}{11}$, 0)              |\n",
    "|2         |(0,1,0,0,0)  |\n",
    "|3      |($\\frac{24}{143}$,$\\frac{5}{13}$,0,$\\frac{64}{143}$, 0)       |\n",
    "|4      |($\\frac{3}{11}$,0,0,$\\frac{8}{11}$, 0)               |\n",
    "|5      |($\\frac{18}{143}$,$\\frac{7}{13}$,0,$\\frac{48}{13}$, 0)     |\n",
    "\n",
    "If we compare these to the plots we produced previously we observe that the Markov chain converges to the limit distribution dependent on the initial state as expected. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
